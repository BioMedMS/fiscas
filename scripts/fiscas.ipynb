{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58d95f6",
   "metadata": {},
   "source": [
    "# FISCAS\n",
    "***\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This python based program can be used to combine MALDI imaging data with microscope images to: \n",
    "1. overlay maldi images with microscope images \n",
    "2. perform a cell segmentation (based on Cellprofiler)\n",
    "3. calculate single cell mass spectra based on the previous 2 steps\n",
    "\n",
    "To do so in a user friendly environment this program is implented in Jupyter-lab. \n",
    "\n",
    "\"JupyterLab is the latest web-based interactive development environment for notebooks, code, and data. Its flexible interface allows users to configure and arrange workflows in data science, scientific computing, computational journalism, and machine learning.\" --- jupyter.org\n",
    "\n",
    "Jupyter-Lab is easy to use even without any programming experience. The interactive environment makes an intuitive workflow possible and minimizes running time while testing different run settings.\n",
    "A Jupyter Notebook is splitted into many chunks called cells. These cells can either contain text (like this one here) or code. \n",
    "To run the program you can simply run one cell after the other by clicking the run button ‚ñ∂Ô∏è or hitting `shift + enter` on the keyboard. By doing so you tell the program to run the current cell and move to the next one. The current cell is indicated by a vertical blue line on the left of the cell. You can also run multiple cells consecutively by marking multiple cells and hitting the run button. Every code cell has quare brackets in the upper left corner `[]`. The brackets are empty if the cell hasn't been run before. Once you run a cell a little asterisk `*` appears in the brackets to indicate that the cell is running. Once it is done, the asterisk is replaced by a consecutive number. One thing to note is that all variables of the program are stored in the random-access memory (RAM) of your system. Depending on your image sizes this can take up a lot of the systems memory. The occupied memory won't be freed until you either shut down Jupyter Notebook, or restart the kernel. You can do so under the Kernel tab in the upper left corner of your browser.  \n",
    "\n",
    "So let's try to import all the required packages the program needs by running the first code cell. \n",
    "\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9003585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import copy\n",
    "import timeit\n",
    "import time\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import widgets\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "\n",
    "\n",
    "#specific imports\n",
    "import skimage\n",
    "import skimage.filters as filters\n",
    "from skimage.transform import resize\n",
    "import scipy\n",
    "from scipy.ndimage import rotate\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import imageio\n",
    "import cellprofiler_core.pipeline\n",
    "import cellprofiler_core.preferences\n",
    "import cellprofiler_core.utilities.java\n",
    "import cellprofiler.modules\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from pyimzml.ImzMLParser import ImzMLParser, getionimage\n",
    "except:\n",
    "    print(\"failed to import pyimzml\")\n",
    "    pass\n",
    "try:\n",
    "    from scilslab import LocalSession \n",
    "    import scilslab\n",
    "except:\n",
    "    print(\"failed to import SCiLS API\")\n",
    "    pass \n",
    "\n",
    "print(\"all modules imported successfully\")\n",
    "print(\"\\n Congratulations, you did it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b40ce4",
   "metadata": {},
   "source": [
    "Let's do it again. The next cells are just for good looking of the tables and graphs and some minor settings for the program üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07a5ac-feed-486b-b556-d318d0f42e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table{float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccba27-d8d5-49f8-a784-9c72b628f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d8bf9-3a93-4d3f-ad0f-981467763bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_vm = False\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db16f3",
   "metadata": {},
   "source": [
    "Now lets define the paths to your images. Feel free to replace some of these paths according to your own data. For the import you have three different options (.csv, .slx, .imzml) so you don't need to provide path variables for all of them.\n",
    "The microscope images should be as large as necessary (enclosing the maldi image) and as small as possible to reduce memory usage and runtime. \n",
    "The following table contains the abbreviations used for the variable names of the path variables. On the bottom of the document is a complete list with all abbreviations used in the program.\n",
    "\n",
    "| abbreviation | long form |\n",
    "| :- | :- |\n",
    "| bf | bright field |\n",
    "| mem | membrane |\n",
    "| nuc | nuc |\n",
    "| lic | license (SCiLS) |\n",
    "| pipe | pipeline (Cellprofiler) |\n",
    "| dir | directory |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e03de4-8e08-4ff2-a5fd-5a4d55c197f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and variables\n",
    "output_dir = os.path.abspath(\"./path/to/results/\") # directory in which all results will be saved\n",
    "input_dir = os.path.abspath(\"./path/to/data/\") # directory where all the needed files are\n",
    "\n",
    "# Cellprofiler \n",
    "pipe_dir = input_dir + \"/pipeline_name\"\n",
    "plugin_dir = os.path.abspath(r\"./path/to/cellprofiler/plugins/\")\n",
    "# paths to files\n",
    "path_bf = input_dir + \"/brightfield_image\"\n",
    "path_mem = input_dir + \"/membrane_image\"\n",
    "path_nuc = input_dir + \"/nuclei_image\"\n",
    "peak_list = input_dir + \"/peakList\"\n",
    "\n",
    "#imzml_import\n",
    "imzml_file = input_dir + \"/imzml_file\"\n",
    "\n",
    "lic_path = \"./lic.txt\"\n",
    "lic = \"\"\n",
    "if len(lic)<5:\n",
    "    try:\n",
    "        print(\"reading license from {}\".format(lic_path))\n",
    "        with open(lic_path) as f:\n",
    "            lines = f.readlines()\n",
    "            lic =  lines[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"please provide a valid license\")\n",
    "\n",
    "#csv_import\n",
    "path_spots = input_dir + \"/spots_csv\"\n",
    "path_spectra = input_dir + \"/spectra_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f15ecc-21de-4547-b772-d38ec113c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-Up Cellprofiler\n",
    "cellprofiler_core.preferences.set_headless()\n",
    "cellprofiler_core.preferences.set_plugin_directory(plugin_dir)\n",
    "# Start the Java VM\n",
    "if java_vm == False:\n",
    "    print(\"starting java virtual machine\")\n",
    "    cellprofiler_core.utilities.java.start_java()\n",
    "    java_vm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeeff9c",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Now its time to change the program settings accordingly to your own measurement. \n",
    "- General settings\n",
    "    - `um_per_pixel_mic` corresponds to the resolution of the microscope and is measured in ¬µm/pixel\n",
    "    - `um_per_pixel_ms` is the pixel size of the maldi measurement in ¬µm/pixel\n",
    "    - `img_res` is the common resolution that all images will be scaled to during the overlay, to match each other; It is measured in ¬µm \n",
    "- Overlay settings\n",
    "    - `overlay_peak` corresponds to the *m/z* of the maldi image which will be used for the overlay; it should be an intense signal that is homogenously distributed throughout the cells\n",
    "    - `rotation_overlay` can be turned on to improve the overlay result by rotating the image in a specified range to correct minor rotation differences between the maldi and microscope images\n",
    "- Single cell mass spectra settings\n",
    "    - `rim_pixel_correction` can be turned on to scale maldi intensities that only hit cells partially, according to their hit area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ff7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings\n",
    "#um_per_pixel_mic = 0.334992 # resolution of the microscope in micrometer/pixel\n",
    "um_per_pixel_mic = 0.344 # empirically determined; it delivers better results since it makes up for imprecisions in the MALDI stage; the original value above will work as well just not as good as this one\n",
    "pixel_area_mic = um_per_pixel_mic * um_per_pixel_mic\n",
    "um_per_pixel_ms = 8 # resolution of the ms image in micrometer/pixel\n",
    "img_res = 2 # resolution that is used for scaling the images to a uniform size in micrometer; greatly influences the running time of the overlay\n",
    "\n",
    "# overlay settings\n",
    "overlay_peak = 577.5168 # m/z at which the overlay is performed\n",
    "rotation_overlay = True\n",
    "rotation_val = 25\n",
    "if rotation_overlay == True and not rotation_val:\n",
    "    rotation_val = int(input(\"rotation_overlay: How many steps should be used for image rotation? (1 step = 0.1 degree)\"))\n",
    "\n",
    "\n",
    "# single cell mass spectra settings\n",
    "rim_pixel_correction = False # if turned on intensities of ms pixels that only cover the cells partially will be scaled accordingly to the hit area\n",
    "mic_scale_factor = um_per_pixel_mic / img_res\n",
    "ms_scale_factor = um_per_pixel_ms / img_res\n",
    "ms_to_mic = ms_scale_factor / mic_scale_factor\n",
    "if ms_scale_factor.is_integer():\n",
    "    ms_scale_factor = int(ms_scale_factor)\n",
    "else:\n",
    "    raise Exception(\"the img_res must be a common divisor of um_per_pixel_ms\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176636f",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Now we need to define all the functions that are used in the program. You can just run these cells one after another. There is no cool output to look at. \n",
    "\n",
    "For all programmers who read this you are welcome to look in these functions and tweak them here and there to fit your purpose. If you find any bugs or have suggestions for a more efficient way of solving this, you are very welcome to post them on the corresponding github page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da533384-c90b-4876-b6fb-176d7cfb8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function wrapper to measure the time of a function\n",
    "def time_report(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = timeit.default_timer()\n",
    "        result = func(*args, **kwargs)\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"Function \\\"{a}\\\" took {b} to run\".format(a=func.__name__,b=datetime.timedelta(seconds=(stop-start))))\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299845d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports MS Data from csv files; spot_file contains pixel ids with x and y coordinates; \n",
    "# spectra_file contains m/z and intensities for every pixel; peak_list_file contains an \n",
    "# optional peak List which will be used to reduce the mass list;\n",
    "# returns the mass list and an image with all intensities as numpy arrays\n",
    "\n",
    "def calculate_idx(x,y,x_min,y_min):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    j = int(np.round((y - y_min)/um_per_pixel_ms)) \n",
    "    i = int(np.round((x - x_min)/um_per_pixel_ms))\n",
    "    return i, j\n",
    "\n",
    "\n",
    "\n",
    "@time_report\n",
    "def csv_import(spot_file, spectra_file, peak_list_file=None): \n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    with open(spot_file) as f:\n",
    "        reader = csv.reader(f, delimiter = ';')\n",
    "        l = 0\n",
    "        for row in reader:\n",
    "            if l > 8:\n",
    "                x.append(float(row[1]))\n",
    "                y.append(float(row[2]))\n",
    "            l = l + 1\n",
    "        spots = np.zeros(((l-9),3), dtype = int)\n",
    "    x_min = min(x)\n",
    "    x_max = max(x)\n",
    "    y_min = min(y)\n",
    "    y_max = max(y)\n",
    "    dx = np.absolute(int(np.round((x_max - x_min)/um_per_pixel_ms))) + 1\n",
    "    dy = np.absolute(int(np.round((y_max - y_min)/um_per_pixel_ms))) + 1\n",
    "\n",
    "\n",
    "    with open(spot_file) as f:\n",
    "        reader = csv.reader(f, delimiter = ';')\n",
    "        l = 0\n",
    "        for row in reader:\n",
    "            if l > 8:            \n",
    "                x, y = calculate_idx(float(row[1]), float(row[2]), x_min, y_min)\n",
    "                spots[l-9, 0] = int(l - 9)\n",
    "                spots[l-9, 1] = x\n",
    "                spots[l-9, 2] = y\n",
    "            l = l + 1\n",
    "    #spots = np.flip(spots, axis=1)\n",
    "    num_spots = len(spots)\n",
    "    print(\"num_spots: {}\".format(num_spots))\n",
    "        \n",
    "    # creates the mass and intensity list\n",
    "    with open(spectra_file) as data:\n",
    "        csv_reader = csv.reader(data, delimiter = ';')\n",
    "        line = 0\n",
    "        for row in csv_reader:\n",
    "            if line == 10:\n",
    "                mass_list = np.zeros((len(row)-1)) # list with all m/z \n",
    "                intensity_list = np.zeros((num_spots,len(row)-1)) # list with intensities of all pixels and all m/z\n",
    "                for j in range(0, len(row)-1):\n",
    "                    mass_list[j]=float(row[j+1])\n",
    "            if line > 10:\n",
    "                for j in range(0, len(row)-1):\n",
    "                    intensity_list[line-11,j]=int(row[j+1])\n",
    "            line += 1\n",
    "\n",
    "    # shapes the intensity list to the size of the actual image.\n",
    "    print(\"len mass list: {}\".format(len(mass_list)))\n",
    "    img_all_int = np.zeros((dy,dx,len(mass_list))) # image with intensities for every m/z for all pixels\n",
    "    y_max = np.max(spots[2])\n",
    "    for idx, x, y in spots:\n",
    "        img_all_int[y_max - y,x,:]=intensity_list[idx,:] \n",
    "    \n",
    "    # reduces the number of peaks by combining neighbouring peaks corresponding to the peak list\n",
    "    if peak_list_file:\n",
    "        with open(peak_list_file) as data:\n",
    "            csv_reader = csv.reader(data, delimiter=';')\n",
    "            line = 0\n",
    "            for row in csv_reader:\n",
    "                line += 1\n",
    "            length_peak_list = line-9\n",
    "            \n",
    "        peak_list = np.zeros((length_peak_list, 2))\n",
    "        with open(peak_list_file) as data:\n",
    "            csv_reader = csv.reader(data, delimiter=';')\n",
    "            line = 0\n",
    "            for row in csv_reader:\n",
    "                if line > 8:\n",
    "                    peak_list[line-9,0] = row[0]\n",
    "                    peak_list[line-9,1] = row[1]\n",
    "                line += 1\n",
    "        \n",
    "        img_all_comp = np.zeros((dy, dx, len(peak_list)))\n",
    "        for i in tqdm(range(len(peak_list)), desc='Loading...'):\n",
    "            j_list = []\n",
    "            for j in range(i,len(mass_list)):\n",
    "                if mass_list[j] > (peak_list[i,0] - peak_list[i,1]) and mass_list[j] < (peak_list[i,0] + peak_list[i,1]):\n",
    "                    j_list.append(j)\n",
    "            img_all_comp[:,:,i] = np.sum(img_all_int[:,:, j_list[0] : j_list[-1] + 1], axis=2)\n",
    "        return peak_list[:,0], img_all_comp\n",
    "            \n",
    "    return mass_list, img_all_int  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6a49c-e0a2-464e-b5ba-abb62aad74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MS data directly from scils file\n",
    "# returns the mass list and an image with all intensities as numpy arrays\n",
    "# peaklist is here mandatory but if none is given you will be requested to choose one from your scils file\n",
    "\n",
    "@time_report\n",
    "def scils_import(lic, scils_file, peaklist_name=None):\n",
    "    \n",
    "    os.environ[\"SCILSMSSERVER_LICENSE\"] = lic\n",
    "    with LocalSession(filename = scils_file) as session:\n",
    "\n",
    "        try:\n",
    "            dataset = session.dataset_proxy\n",
    "            no_peaklist = True\n",
    "            peaklists = dataset.get_peak_lists()\n",
    "\n",
    "            while no_peaklist:\n",
    "\n",
    "                if peaklist_name:\n",
    "                    for plist in peaklists:\n",
    "                        if plist.name == peaklist_name:\n",
    "                            peaklist = plist.intervals\n",
    "                            no_peaklist = False\n",
    "                    if no_peaklist:\n",
    "                        peaklist_name = None\n",
    "\n",
    "                else:     \n",
    "                    print(\"Available peaklists: \\n\")\n",
    "                    for plist in peaklists:\n",
    "                        print(plist.name)\n",
    "\n",
    "                    peaklist_name = str(input(\"\\n Enter a valid peaklist to proceed\"))\n",
    "\n",
    "                    for plist in peaklists:\n",
    "                        if plist.name == peaklist_name:\n",
    "                            peaklist = plist.intervals\n",
    "                            no_peaklist = False\n",
    "\n",
    "\n",
    "            num_of_peaks = len(peaklist)\n",
    "            print(\"importing {} peaks\".format(num_of_peaks))\n",
    "\n",
    "            img = dataset.get_ion_images(peaklist[0][0], peaklist[0][1])[0].values\n",
    "            mass_list = np.zeros(num_of_peaks, dtype=float)\n",
    "            img_all_int = np.zeros((len(img), len(img[0]), num_of_peaks), dtype=float)\n",
    "\n",
    "            i=0\n",
    "            for peak in tqdm(peaklist, desc='Loading...'):\n",
    "                mass_list[i] = np.mean((peak[0], peak[1]))\n",
    "                ion_image = dataset.get_ion_images(peak[0], peak[1])[0].values\n",
    "                img_all_int[:,:,i] = np.where(~np.isnan(ion_image), ion_image, 0)\n",
    "                i += 1\n",
    "\n",
    "            return mass_list, img_all_int\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5f333-e213-45fc-b71f-2fe5fae46a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imzml import\n",
    "# takes the .imzml file and a peaklist in .csv format as input\n",
    "\n",
    "@time_report\n",
    "def imzml_import(imzml_file, peaklist_file):\n",
    "    \n",
    "    print(\"starting import\")\n",
    "    try:\n",
    "        with open(peaklist_file) as data:\n",
    "            csv_reader = csv.reader(data, delimiter=';')\n",
    "            line = 0\n",
    "            for row in csv_reader:\n",
    "                line += 1\n",
    "            length_peaklist = line-9\n",
    "            \n",
    "        peaklist = np.zeros((length_peaklist, 2))\n",
    "        with open(peaklist_file) as data:\n",
    "            csv_reader = csv.reader(data, delimiter=';')\n",
    "            line = 0\n",
    "            for row in csv_reader:\n",
    "                if line > 8:\n",
    "                    peaklist[line-9,0] = row[0]\n",
    "                    peaklist[line-9,1] = row[1]\n",
    "                line += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Please provide the path to a valid peaklist.\")\n",
    "   \n",
    "    p = ImzMLParser(imzml_file)\n",
    "    img = getionimage(p, peaklist[0][0], tol=peaklist[0][1])\n",
    "    img_all_int = np.zeros((len(img), len(img[0]), len(peak_list)))\n",
    "    mass_list = np.zeros(len(peak_list))\n",
    "    i = 0\n",
    "    for peak, tolerance in tqdm(peaklist, desc='Loading'):\n",
    "        img_all_int[:,:,i] = getionimage(p, peak, tol=tolerance)\n",
    "        mass_list[i] = peak\n",
    "\n",
    "    return mass_list, img_all_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31da172-cf74-4995-9d5e-f615f2ce9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that coregistrates to images (overlay)\n",
    "# Takes the smaller image as first argument and the larger image as second argument. \n",
    "# Also needs the image resolution of both images and the resolution in micrometer/pixel at which the overlay is performed.\n",
    "# Returns the coordinates at the position with the highest cross correlation and if a rotation correction was performed also the opitmal rotation value\n",
    "\n",
    "@time_report\n",
    "def perform_overlay(ms_img, mic_img, ms_res, mic_res, img_res, rotation_val=0):\n",
    "    # scale ms img to overlay Resolution\n",
    "    print(\"binarizing and scaling images...\")\n",
    "    ms_img_scaled = np.zeros((len(ms_img)*ms_scale_factor,len(ms_img[0])*ms_scale_factor)) \n",
    "    for i in range(len(ms_img)):\n",
    "        for j in range(len(ms_img[0])):\n",
    "            ms_img_scaled[i*ms_scale_factor:i*ms_scale_factor+ms_scale_factor, \n",
    "                          j*ms_scale_factor:j*ms_scale_factor+ms_scale_factor] = ms_img[i,j]\n",
    "    # scale microscopy img to overlay Resolution\n",
    "    mic_img_scaled = resize(mic_img, (int(len(mic_img)*mic_scale_factor), int(len(mic_img[0])*mic_scale_factor))) \n",
    "    # binarize microscopy and ms img for overlay\n",
    "    mic_img_thresh = filters.threshold_otsu(mic_img_scaled) \n",
    "    mic_img_bin = np.zeros((mic_img_scaled.shape))\n",
    "    mic_img_bin[mic_img_scaled>mic_img_thresh]=1\n",
    "    ms_img_thresh = filters.threshold_otsu(ms_img_scaled)\n",
    "    ms_img_bin = np.zeros((ms_img_scaled.shape))\n",
    "    ms_img_bin[ms_img_scaled>ms_img_thresh]=1\n",
    "    \n",
    "    print(\"performing overlay...\")\n",
    "    overlay = scipy.signal.correlate2d(mic_img_bin, ms_img_bin, mode='valid', boundary='fill', fillvalue=0)\n",
    "    y_over, x_over = np.unravel_index(np.argmax(overlay), overlay.shape)\n",
    "    \n",
    "    # rotates the image in 0.1 degree steps and optimizes for best 2d correlation\n",
    "    if rotation_val != 0:\n",
    "        rot_eval = np.zeros((rotation_val*2 + 1,2))\n",
    "        overlay_rot_padding = 20\n",
    "        # use previous overlay as start point for rotation and use only a subset of the microscope image, depending on padding range.\n",
    "        mic_img_bin_cut = mic_img_bin[y_over - overlay_rot_padding : y_over + len(ms_img_bin) + overlay_rot_padding,\n",
    "                                     x_over - overlay_rot_padding : x_over + len(ms_img_bin[0]) + overlay_rot_padding]\n",
    "        rot_opt_value = 0\n",
    "        rot_opt = 0\n",
    "        # for loop to calculate 2d correlation for every rotation value\n",
    "        for rot in tqdm(range(-rotation_val, rotation_val + 1), desc='performing rotation...'):\n",
    "            ms_img_bin_rot = rotate(ms_img_bin, rot*0.1, reshape=False)\n",
    "            overlay_rot = scipy.signal.correlate2d(mic_img_bin_cut, ms_img_bin_rot, \n",
    "                                                   mode='valid', boundary='fill', fillvalue=0)\n",
    "            rot_eval[rot + rotation_val, 0] = rot*0.1\n",
    "            rot_eval[rot + rotation_val, 1] = np.max(overlay_rot)\n",
    "            if np.max(overlay_rot) > rot_opt_value:\n",
    "                rot_opt = rot*0.1\n",
    "                rot_opt_value = np.max(overlay_rot)\n",
    "        print(\"optimal Rotation: {}\".format(rot_opt))\n",
    "        # perform final overlay with optimal rotation\n",
    "        ms_img_bin_unrotated = ms_img_bin\n",
    "        ms_img_bin = rotate(ms_img_bin, rot_opt, reshape=False)\n",
    "        overlay = scipy.signal.correlate2d(mic_img_bin, ms_img_bin, mode='valid', boundary='fill', fillvalue=0)\n",
    "        y_over, x_over = np.unravel_index(np.argmax(overlay), overlay.shape)\n",
    "        \n",
    "        # plot rotation evaluation\n",
    "        plt.figure()\n",
    "        plt.title(\"rotation evaluation\")\n",
    "        plt.plot(rot_eval[:,0], rot_eval[:,1], '.')\n",
    "        plt.savefig(output_dir + \"/images/rotation_evaluation.jpg\", dpi=300)\n",
    "        \n",
    "    # plot results\n",
    "    overlay_img = np.zeros((len(mic_img_bin), len(mic_img_bin[0]), 3))\n",
    "    overlay_img[:,:,0] = mic_img_bin\n",
    "    overlay_img[y_over : y_over + len(ms_img_bin), x_over : x_over + len(ms_img_bin[0]), 1] = ms_img_bin[:,:]     \n",
    "    plt.figure()\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"overlay\")\n",
    "    plt.plot(x_over, y_over, 'r+')\n",
    "    plt.savefig(output_dir +  \"/images/overlay.jpg\", dpi=300)\n",
    "    plt.figure()\n",
    "    plt.title(\"binary overlay image\")\n",
    "    plt.imshow(overlay_img)\n",
    "    plt.savefig(output_dir + \"/images/overlay_img.jpg\", dpi=300)\n",
    "    \n",
    "    if rotation_val != 0:\n",
    "        return (x_over, y_over, rot_opt)\n",
    "    else:\n",
    "        return (x_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87475b58-363f-4759-a4f3-02a3c026c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Cellprofiler to provide a cell segmentation based on the fluorescence images\n",
    "# Takes a Cellprofiler pipeline as an input \n",
    "# Optional Arguments are the option to overwrite other files (default is yes) and the file format of the output (.npy or .tiff)\n",
    "\n",
    "@time_report\n",
    "def cellprofiler_segment(pipe_dir=pipe_dir, overwrite_results='yes', output_file_format='npy'):\n",
    "\n",
    "    # Open a pipeline\n",
    "    pipeline = cellprofiler_core.pipeline.Pipeline()\n",
    "    pipeline.load(pipe_dir)\n",
    "    # Set output directory\n",
    "    saving_path = pathlib.Path(output_dir)\n",
    "    cellprofiler_core.preferences.set_default_output_directory(output_dir)\n",
    "    print(f\"Data will be saved to: {output_dir}\")\n",
    "    #Loading images\n",
    "    input_path = pathlib.Path(input_dir)\n",
    "    file_list = list(input_path.glob('*cut.tif'))\n",
    "    print(\"Number of images:\", len(file_list))\n",
    "    files = [file.as_uri() for file in file_list]\n",
    "    print(files)\n",
    "    pipeline.read_file_list(files)\n",
    "    # overwrite data\n",
    "    for module in pipeline.modules():\n",
    "        if type(module) == cellprofiler.modules.saveimages.SaveImages:\n",
    "            module.overwrite.set_value('Yes')\n",
    "            #module.setting(12).set_value(overwrite_results)\n",
    "            module.setting(9).set_value(output_file_format)\n",
    "        elif type(module) == cellprofiler.modules.exporttospreadsheet.ExportToSpreadsheet:\n",
    "            #module.setting(18).set_value(overwrite_results)\n",
    "            module.wants_overwrite_without_warning.set_value('Yes')\n",
    "\n",
    "    #Running the pipeline\n",
    "    output_measurements = pipeline.run()\n",
    "    \n",
    "    \n",
    "    # Load saved images\n",
    "    color_images = list(saving_path.glob('*Color.npy'))\n",
    "    WGA_images = list(saving_path.glob('*WGA_label.npy'))\n",
    "    nuclei_images = list(saving_path.glob('*Nuc_label.npy'))\n",
    "\n",
    "    cell_marker_cut = np.load(WGA_images[0])\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols= 3, figsize=(15, 10))\n",
    "    axes[0].imshow(np.load(color_images[0]))\n",
    "    axes[0].set_title(\"Segmentation\")\n",
    "    axes[1].imshow(cell_marker_cut)\n",
    "    axes[1].set_title(\"WGA Label Image\")\n",
    "    axes[2].imshow(np.load(nuclei_images[0])) \n",
    "    axes[2].set_title(\"Nuclei Label Image\")\n",
    "    for ax in axes:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "\n",
    "\n",
    "    cell_marker_scaled_cut = cv2.resize(cell_marker_cut, dsize=(ms_scaled_shape[1], ms_scaled_shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    cell_marker_masked_scaled_cut = np.ma.masked_where(cell_marker_scaled_cut < 0.95, cell_marker_scaled_cut)\n",
    "    np.savez_compressed(output_dir + \"/cell_marker_masked_scaled_cut\", data = cell_marker_masked_scaled_cut, mask=cell_marker_masked_scaled_cut.mask)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cell_marker_masked_scaled_cut)\n",
    "\n",
    "    return cell_marker_masked_scaled_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67671b3a",
   "metadata": {},
   "source": [
    "### Run the program\n",
    "\n",
    "Now the time has come to actually run the program. Let's start with importing you mass spectra by running one of the next 3 cells. Depending on your data size and the format you import the data from this may take a while. \n",
    "\n",
    "#### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c4710-95c9-43b5-bddc-cebfd934d5a0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "You can import your data via csv files (only tested for csv files generated by SCiLS; t = 37 s), SCiLS files (.slx; t = 21 s) and imzml files (t = 33 min 23 s). The running times were measured with the test sample set of 16993 pixels and 502 mass features. If an .slx file and a SCiLS license is available the SCiLS import is recommended. For the SCiLS import you either need to assign the license number to the variable 'lic' in the sections where the paths are defined, or you need to provide a path to a text file which contains only the license number.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e23cf-23b1-4c34-92d5-92202c425793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCiLS import via SCiLS API\n",
    "# please do not interrupt the kernel during import. If you do, you need to restart the kernel \n",
    "# before you can retry to properly close the scils session\n",
    "# otherwise the file be blocked by the licensing software due to incomplete closing of the prior session \n",
    "\n",
    "try:\n",
    "    #test if mass_list and ms_img_all_int already exist\n",
    "    mass_list.shape\n",
    "    ms_img_all_int.shape\n",
    "    print(\"The data is already imported. If you want to reimport, restart the kernel or run the the import seperately.\")\n",
    "except:\n",
    "    mass_list, ms_img_all_int = scils_import(lic, scils_file, \"500peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93638501-8118-45e2-824b-cb7be08157dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv import\n",
    "\n",
    "try:\n",
    "    #test if mass_list and ms_img_all_int already exist\n",
    "    mass_list.shape\n",
    "    ms_img_all_int.shape\n",
    "    print(\"The data is already imported. If you want to reimport, restart the kernel or run the the import seperately.\")\n",
    "except:\n",
    "    mass_list, ms_img_all_int = csv_import(path_spots, path_spectra, peak_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf0c62-dd0c-4039-b6a0-e64837f3de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imzml import via pyimzml\n",
    "# compared to the other methods very slow\n",
    "\n",
    "try:\n",
    "    #test if mass_list and ms_img_all_int already exist\n",
    "    mass_list.shape\n",
    "    ms_img_all_int.shape\n",
    "    print(\"The data is already imported. If you want to reimport, restart the kernel or run the the import seperately.\")\n",
    "except:\n",
    "    mass_list, ms_img_all_int = imzml_import(imzml_file, peaklist_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e0ce3",
   "metadata": {},
   "source": [
    "#### Prepare microscope images for overlay\n",
    "\n",
    "The next step is the import of the microscope images and to adjust their contrast prior to the overlay. This contrast enhancement is needed for the overlay to ensure that the binarization will work. It is done by rescaling the lowest and highest intensities to the minimal and maximal value that is possible (`.rescaling_intensity()`). You can check the results in the cell below. If the results doesn't look to good or you have some other contrast enhancement method you want to use feel free to change it. Here are some options from the skimage pack that you could try:\n",
    "-  `skimage.exposure.rescale_intensity(mem_img)`\n",
    "-  `skimage.exposure.equalize_hist(mem_img)`\n",
    "-  `skimage.exposure.equalize_adapthist(mem_img)`\n",
    "- `skimage.exposure.adjust_gamma(mem_img)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf72b2-147b-4b14-a82f-60d2540cebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_img = imageio.v2.imread(path_mem)\n",
    "nuc_img = imageio.v2.imread(path_nuc)\n",
    "bf_img = imageio.v2.imread(path_bf) \n",
    "    \n",
    "mem_img_cont = skimage.exposure.rescale_intensity(mem_img)\n",
    "nuc_img_cont = skimage.exposure.rescale_intensity(nuc_img)\n",
    "bf_img_cont = skimage.exposure.rescale_intensity(bf_img)\n",
    "\n",
    "fix, ax = plt.subplots(2,2, figsize=(8,8))\n",
    "ax[0,0].imshow(mem_img[:1000,:1000], cmap = 'gray', vmin=0, vmax=65535)\n",
    "ax[0,0].title.set_text(\"original membrane image\")\n",
    "ax[0,1].imshow(nuc_img[:1000,:1000], cmap = 'gray', vmin=0, vmax=65535)\n",
    "ax[0,1].title.set_text(\"original nuclei image\")\n",
    "ax[1,0].imshow(mem_img_cont[:1000,:1000], cmap = 'gray', vmin=0, vmax=65535)\n",
    "ax[1,0].title.set_text(\"scaled membrane image\")\n",
    "ax[1,1].imshow(nuc_img_cont[:1000,:1000], cmap = 'gray', vmin=0, vmax=65535)\n",
    "ax[1,1].title.set_text(\"scaled nuclei image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe05b86",
   "metadata": {},
   "source": [
    "Now that we are prepared we can run the actual overlay. The next cell generates an image of the `overlay_peak` which you specified above and prints it out on the screen so you can check if you are happy with the distribution for your overlay. The cell after that will then perform the overlay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b45317-210f-41b8-b54c-72bdbf4c368c",
   "metadata": {},
   "source": [
    "#### Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82055771-78c8-46e5-a1b3-0617b609da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_overlay_peak = 0\n",
    "for i in range(len(mass_list) - 1):\n",
    "    if abs(mass_list[i+1] - overlay_peak) < abs(mass_list[i] - overlay_peak):\n",
    "        idx_overlay_peak = i + 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "ms_img = ms_img_all_int[:,:,idx_overlay_peak]\n",
    "#ms_img = np.flipud(ms_img)\n",
    "plt.figure()\n",
    "plt.imshow(ms_img)\n",
    "plt.title(\"m/z {}\".format(mass_list[idx_overlay_peak]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c14981",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Depending on your resolution settings and the size of the image the next step can take between a few minutes to several hours so maybe start with a lower resolution (higher values) first and then increase the resolution when you know that everything works.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a148199-5274-4ff9-bede-607ebe863dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_result = perform_overlay(ms_img, mem_img_cont, um_per_pixel_ms, um_per_pixel_mic, img_res, rotation_val=rotation_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83071b8",
   "metadata": {},
   "source": [
    "What to do if the overlay didn't work at all:\n",
    "1. Make sure that your maldi image can really be found in your microscopy image\n",
    "2. Check if the overlay image matches the pattern of your microscopy image (some microscopy images may be flipped compared to the MALDI image)\n",
    "3. Check if the scaling factors for the maldi resolution and microscopy resolution are correct\n",
    "4. Turn on the rotation correction for the overlay\n",
    "5. increase the resolution\n",
    "\n",
    "If your Overlay performed well you can continue with the segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee57dfd",
   "metadata": {},
   "source": [
    "Since the overlay told us exactly were our MALDI image is positioned on the microscope image we can use only that part for the segmentation. By cutting down the microscope image to the needed size we will reduce memory usage and increase the segmentation speed by a lot. Since we don't want to have any artifacts on the borders we don't cut down all the way to the borders of the maldi image, but rather leave some space in between to circumvent these problems. This is called padding. The default value for padding is here set to 5% of the maldi image but feel free to change it, if it seems appropriate to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7b6dc-074a-477b-b9f7-fe7027681941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mic_scaled_shape = (int(len(mem_img)*mic_scale_factor), int(len(mem_img[0])*mic_scale_factor))\n",
    "ms_scaled_shape = (int(len(ms_img)*ms_scale_factor), int(len(ms_img[0])*ms_scale_factor))\n",
    "\n",
    "\n",
    "mem_img_cut = mem_img_cont[int(overlay_result[1] / mic_scale_factor) : int((overlay_result[1] + ms_scaled_shape[0]) / mic_scale_factor),\n",
    "                     int(overlay_result[0] / mic_scale_factor) : int((overlay_result[0] + ms_scaled_shape[1]) / mic_scale_factor)\n",
    "                     ]\n",
    "nuc_img_cut = nuc_img_cont[int(overlay_result[1] / mic_scale_factor) : int((overlay_result[1] + ms_scaled_shape[0]) / mic_scale_factor),\n",
    "                     int(overlay_result[0] / mic_scale_factor)  : int((overlay_result[0] + ms_scaled_shape[1]) / mic_scale_factor)\n",
    "                     ]\n",
    "\n",
    "im = Image.fromarray(nuc_img_cut)\n",
    "im.save(input_dir + '/nuc_C2_cut.tif')\n",
    "im = Image.fromarray(mem_img_cut)\n",
    "im.save(input_dir + '/mem_C1_cut.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78dca8b",
   "metadata": {},
   "source": [
    "#### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5e86e-fda1-4860-88bc-69991cedcfe0",
   "metadata": {},
   "source": [
    "The segmentation is performed with Cellprofiler.\n",
    "Cellprofiler is a very powerfull tool for segmenting and analyzing microscope images of cells. The Standard workflow would be to open Cellprofiler first with a small test image of your cells. Generate a pipeline that is capable of segmenting your testset and saves you all the measurements you want to do on your microscopy images. Then export the pipeline so it can be used by python. If you need any help with using cellprofiler you can find it on https://cellprofiler.org. They have a lot of helpful examples and tutorials to look into and an extensive manual where you can find explantions for all of the functionallity that cellprofiler provides. The important part in the pipeline is that images with `*Color.tif`, `*WGA_label.npy` and `*Nuc_label.npy` are exported, because they will be reopenend and used by the rest of the program. If you change the names in the Cellprofiler pipeline you would need to change them as well in the segmentation function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a276e9-e9e2-465b-bd94-adaa778a8fdb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_marker_masked_scaled_cut = cellprofiler_segment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844fa9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exploratory Data Analysis\n",
    "Uncomment the next cell to print the results of the morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b91acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "files = []\n",
    "for filename in os.listdir(output_dir + \"/segmentation/\"):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        files.append(os.path.join(output_dir, filename))\n",
    "        print(filename)\n",
    "# Experiment.csv contains key:value pairs about the analysis pipeline (CP version, imagetypes)\n",
    "experiment = pd.read_csv(files[0], delimiter=\",\", encoding_errors=\"ignore\")\n",
    "print(experiment.head(2))\n",
    "# Image.csv contains measurements on all analysed images (cell counts, execution times, image dimensions )\n",
    "image = pd.read_csv(files[1], delimiter=\",\", encoding_errors=\"ignore\")\n",
    "print(image.shape)\n",
    "print(image.head(2))\n",
    "# Nuclei_Seg_Filtered.csv.csv contains measurements on all analysed objects nuclei (area etc)\n",
    "nuclei_seg = pd.read_csv(files[3], delimiter=\",\", encoding_errors=\"ignore\")\n",
    "print(nuclei_seg.shape)\n",
    "print(nuclei_seg.head(2))\n",
    "# WGA_Seg_Filtered.csv contains measurements on all analysed objects cells (area etc)\n",
    "wga_seg = pd.read_csv(files[6], delimiter=\",\", encoding_errors=\"ignore\")\n",
    "print(wga_seg.shape)\n",
    "print(wga_seg.head(2))\n",
    "# RelateObjects.csv contains Idkw\n",
    "rel_obj = pd.read_csv(files[4], delimiter=\",\", encoding_errors=\"ignore\")\n",
    "print(rel_obj.shape)\n",
    "print(rel_obj.head(2))\n",
    "print(image.iloc[:, 0:4].describe())\n",
    "for i in image.iloc[:, 0:4]:\n",
    "    sns.violinplot(y=image[i], data=image)\n",
    "    sns.swarmplot(y=image[i], data=image, color=\"white\")\n",
    "    plt.show()\n",
    "#Selected measurements\n",
    "col_plot = [\"AreaShape_Area\", \"AreaShape_Compactness\", \"AreaShape_ConvexArea\", \"AreaShape_Eccentricity\", \"AreaShape_FormFactor\", \n",
    "\"AreaShape_MaximumRadius\", \"AreaShape_MeanRadius\", \"AreaShape_MedianRadius\", \"AreaShape_MinFeretDiameter\", \n",
    "\"AreaShape_MinorAxisLength\", \"AreaShape_Orientation\", \"AreaShape_Perimeter\", \"AreaShape_Solidity\"]\n",
    "\n",
    "#View all measurements with: \n",
    "#print(output_measurements.get_measurement_columns())\n",
    "for i in col_plot:\n",
    "    print(i)\n",
    "    print(wga_seg[i])\n",
    "    sns.violinplot(y=wga_seg[i], data=wga_seg)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeda3d7",
   "metadata": {},
   "source": [
    "#### Single Cell Mass spectra Calculation\n",
    "The next step will sort out any pixels that hit more than one cell and if the `rim_pixel_correction` is set to `True` it will also scale the signal intensities of pixels that only hit the cell partially, according to the hit area.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a4301-2f09-4c55-ad2f-2865c2048295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maldi pixel correction; Sort out unambigious pixel and correct pixel that hit cells only partially \n",
    "\n",
    "\n",
    "#cell_marker_masked = np.ma.masked_where(cell_marker < 1.05, cell_marker)\n",
    "#mic_scaled_shape = (int(len(cell_marker)*mic_scale_factor), int(len(cell_marker[0])*mic_scale_factor))\n",
    "#ms_scaled_shape = (int(len(ms_img)*ms_scale_factor), int(len(ms_img[0])*ms_scale_factor))\n",
    "\n",
    "#cell_marker_masked_scaled = np.ma.resize(cell_marker_masked, mic_scaled_shape)\n",
    "#cell_marker_masked_scaled = cv2.resize(cell_marker, dsize=mic_scaled_shape, interpolation=cv2.INTER_NEAREST)\n",
    "#plt.figure()\n",
    "#plt.imshow(cell_marker_masked_scaled)\n",
    "#cell_marker_masked_scaled_cut = cell_marker_masked_scaled[overlay_result[1] : overlay_result[1] + ms_scaled_shape[0], \n",
    "#                                                          overlay_result[0] : overlay_result[0] + ms_scaled_shape[1]]\n",
    "#cell_marker_masked_scaled_cut = cell_marker_masked_scaled_cut - 1\n",
    "#cell_marker_masked_scaled_cut = np.ma.masked_where(cell_marker_masked_scaled_cut < 1, cell_marker_masked_scaled_cut)\n",
    "#plt.figure()\n",
    "#plt.imshow(cell_marker_masked_scaled_cut)\n",
    "\n",
    "ms_img_corr = copy.copy(ms_img_all_int)\n",
    "ms_img_corr_part = np.zeros(ms_img_corr.shape)\n",
    "for i in range(len(ms_img_all_int)):\n",
    "    for j in range(len(ms_img_all_int[0])):\n",
    "        encounterOld = 0\n",
    "        encounterNew = 0\n",
    "        mask_counter = 0\n",
    "        for k in range(ms_scale_factor):\n",
    "            for L in range(ms_scale_factor):\n",
    "                encounterNew = cell_marker_masked_scaled_cut[i*ms_scale_factor + k, j*ms_scale_factor + L]\n",
    "                if encounterOld != 0 and encounterOld != encounterNew and encounterNew != 0:                                                                            \n",
    "                    ms_img_corr[i,j,:] = 0\n",
    "                encounterOld = encounterNew\n",
    "                if cell_marker_masked_scaled_cut[i*ms_scale_factor + k, j*ms_scale_factor + L] > 0:\n",
    "                    mask_counter += 1\n",
    "        if mask_counter > 0 and rim_pixel_correction is True:\n",
    "            ms_img_corr[i,j,:] = ms_img_corr[i,j,:] * ms_scale_factor*ms_scale_factor / mask_counter\n",
    "        ms_img_corr_part[i,j,:] = mask_counter / (ms_scale_factor*ms_scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2f42f",
   "metadata": {},
   "source": [
    "Now it is time for the final step. This one will sum up the intensities of all the pixels that belong to one cell, thereby generating single cell mass spectra. The results will be saved in form of numpy arrays and csv files, to make them accessible for a broad range of statistical analysis tools. Each line will contain a single cell with the intensities of all peaks contained in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f9311-f4ba-4b7a-bb01-6734b78020ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign mass spectra to individual cells\n",
    "\n",
    "mask_max = np.max(cell_marker_masked_scaled_cut)\n",
    "mask_min = np.min(cell_marker_masked_scaled_cut)\n",
    "num_cells = mask_max - mask_min + 1\n",
    "\n",
    "ms_img_corr_scaled = np.zeros((len(ms_img)*ms_scale_factor, len(ms_img[0])*ms_scale_factor, len(mass_list))) \n",
    "print(\"scaling ms image to img_res...\")\n",
    "for i in range(len(ms_img)):\n",
    "    for j in range(len(ms_img[0])):\n",
    "        ms_img_corr_scaled[i*ms_scale_factor : i*ms_scale_factor + ms_scale_factor, j*ms_scale_factor : j*ms_scale_factor + ms_scale_factor, :] = ms_img_corr[i, j, :]\n",
    "        \n",
    "        \n",
    "\n",
    "act_ms_img = np.zeros((ms_scaled_shape[0], ms_scaled_shape[1]))\n",
    "cells_all_mz = np.zeros((num_cells, len(mass_list)))\n",
    "print(\"combining spectra to single-cell spectra...\")\n",
    "for peak_idx in tqdm(range(len(mass_list))):\n",
    "    act_ms_img = ms_img_corr_scaled[:, :, peak_idx]\n",
    "    cells = np.zeros(num_cells)\n",
    "    for i in range(mask_min, mask_max + 1):\n",
    "        cells[i - mask_min] = np.sum(act_ms_img[cell_marker_masked_scaled_cut == i])\n",
    "    cells = np.ma.masked_equal(cells,0)/(ms_scale_factor*ms_scale_factor)\n",
    "    cells_all_mz[:, peak_idx] = cells\n",
    "    \n",
    "print(\"creating compressed array...\")    \n",
    "cells_all_mz_sum = np.zeros((num_cells,))\n",
    "counter = 0\n",
    "for i in range(num_cells):\n",
    "    cells_all_mz_sum[i] = np.sum(cells_all_mz[i,:])\n",
    "    if cells_all_mz_sum[i] != 0:\n",
    "        counter += 1\n",
    "\n",
    "    \n",
    "cells_all_mz_comp = np.zeros((counter, len(mass_list)))\n",
    "j = 0\n",
    "for i in range(0, num_cells):\n",
    "    if cells_all_mz_sum[i] != 0:\n",
    "        cells_all_mz_comp [j] = cells_all_mz[i]\n",
    "        j = j + 1\n",
    "print(\"saving data to {}\".format(output_dir))\n",
    "# save single cell data as numpy arrays and csv files\n",
    "np.save(output_dir + \"/cells_all_mz\", cells_all_mz)\n",
    "np.save(output_dir + \"/cells_all_mz_comp\", cells_all_mz_comp)\n",
    "with open (output_dir + \"/cells_all_mz.csv\", 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cells_all_mz)\n",
    "with open (output_dir + \"/cells_all_mz_comp\", 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(cells_all_mz_comp)\n",
    "    \n",
    "print(\"Job done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a49e69-f10f-4f0f-848f-2bf56c9adc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopping the Java VM\n",
    "if java_vm == True:\n",
    "    cellprofiler_core.utilities.java.stop_java()\n",
    "    java_vm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b6ae3-0e64-420d-995f-4839e0863720",
   "metadata": {},
   "source": [
    "#### Cell picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262344f4-0cbc-410b-97f5-2dca6eb450dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    len(cell_marker_masked_scaled_cut)\n",
    "except:\n",
    "    with np.load(output_dir + \"/cell_marker_masked_scaled_cut.npz\") as npz:\n",
    "        cell_marker_masked_scaled_cut = np.ma.MaskedArray(**npz)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,6)) #necessary, to get mouse events\n",
    "cmap = copy.copy(plt.cm.prism)\n",
    "cmap.set_bad(color='black')\n",
    "im1 = ax[0].imshow(cell_marker_masked_scaled_cut, cmap=cmap, picker=True)\n",
    "text = ax[0].text(-10,-10,\"\", va='bottom', ha='left')\n",
    "bf_img_scaled = resize(bf_img, (int(len(bf_img)*mic_scale_factor), int(len(bf_img[0])*mic_scale_factor)))\n",
    "bf_img_scaled_color = np.zeros((len(bf_img_scaled), len(bf_img_scaled[0]), 3), dtype='int')\n",
    "bf_img_255 = np.uint8((bf_img_scaled / np.max(bf_img_scaled) * 255))\n",
    "bf_img_scaled_color[:,:,0] = bf_img_255\n",
    "bf_img_scaled_color[:,:,1] = bf_img_255\n",
    "bf_img_scaled_color[:,:,2] = bf_img_255\n",
    "\n",
    "def onpick(event):\n",
    "    mouseevent = event.mouseevent\n",
    "    x = int(mouseevent.xdata)\n",
    "    y = int(mouseevent.ydata)\n",
    "    cell_id = cell_marker_masked_scaled_cut[y,x]\n",
    "    txt = \"cell ID: {}\".format(cell_id)\n",
    "    text.set_text(txt)\n",
    "    marked_cell_img = np.zeros((80,80,3))\n",
    "    marked_cell_img = bf_img_scaled_color[(overlay_result[1]+y-40) : (overlay_result[1]+y+40), (overlay_result[0]+x-40) : (overlay_result[0]+x+40)]\n",
    "    cell_marker_masked_scaled_cellPickerCut = cell_marker_masked_scaled_cut[(y-40) : (y+40), (x-40) : (x+40)]\n",
    "    cell_picker_img = copy.copy(marked_cell_img)\n",
    "    cell_picker_img[tuple([cell_marker_masked_scaled_cellPickerCut == (cell_id), 0])] = 255\n",
    "    ax[1].clear()\n",
    "    ax[1].imshow(cell_picker_img)\n",
    "    ax[2].clear()\n",
    "    ax[2].vlines(mass_list,0 , cells_all_mz[cell_id])\n",
    "\n",
    "fig.canvas.mpl_connect('pick_event', onpick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca90d2",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbaaee",
   "metadata": {},
   "source": [
    "### Variable name disclaimer\n",
    "\n",
    "| abbreviation | long form |\n",
    "| :- | :- | \n",
    "| ms | mass spectrometry | \n",
    "| img | image |\n",
    "| mic | microscopy |\n",
    "| res | resolution |\n",
    "| um | micrometer |\n",
    "| rot | rotation |\n",
    "| opt | optimum |\n",
    "| val | value |\n",
    "| eval | evaluation |\n",
    "| nuc | nuclear |\n",
    "| mem | membrane |\n",
    "| bf | brightfield |\n",
    "|thresh | threshold |\n",
    "|cut | cut |\n",
    "|bin | binarized |\n",
    "|blur | blurred |\n",
    "|pos | positions |\n",
    "|dil | dilated |\n",
    "|bg | Background |\n",
    "|fg | foreground |\n",
    "|seg | segmentation |\n",
    "|num | number |\n",
    "|act | actual |\n",
    "|comp | compressed |\n",
    "|corr | corrected |\n",
    "|dc | deepcell |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467bca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
